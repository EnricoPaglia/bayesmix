{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocked Gibbs algorithm + logit SB mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.protobuf.internal.decoder import _DecodeVarint32\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from proto.py.algorithm_state_pb2 import AlgorithmState\n",
    "\n",
    "# Utility to save files with Unix-like newlines\n",
    "def save_np(filename, npobj):\n",
    "    with open(filename, 'wb') as f:\n",
    "        np.savetxt(f, npobj, fmt='%1.5f')\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "# Utility to read file collector, courtesy of\n",
    "# github.com/mberaha/utils/blob/master/proto_utils/py/recordio.py\n",
    "def readManyFromFile(filename, msgType):\n",
    "    out = []\n",
    "    with open(filename, \"rb\") as fp:\n",
    "        buf = fp.read()\n",
    "    n = 0\n",
    "    while n < len(buf):\n",
    "        msg_len, new_pos = _DecodeVarint32(buf, n)\n",
    "        n = new_pos\n",
    "        msg_buf = buf[n:n+msg_len]\n",
    "        try:\n",
    "            msg = msgType()\n",
    "            msg.ParseFromString(msg_buf)\n",
    "            out.append(msg)\n",
    "            n += msg_len\n",
    "        except Exception as e:\n",
    "            break\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim1 = 2\n",
    "n_clus1 = 3\n",
    "x_centers1 = np.column_stack(([-5, 0], [5, 0], [0, 5]))\n",
    "x_var1 = (1.5)**2\n",
    "y_centers1 = [4*_ for _ in range(n_clus1)]\n",
    "y_var1 = 1\n",
    "weights1 = [0.2, 0.2, 0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 200\n",
    "np.random.seed(20201124)\n",
    "# Allocations\n",
    "cc1 = []\n",
    "for c in range(n_clus1):\n",
    "    nn = int(weights1[c] * n1)\n",
    "    cc1.extend(nn * [c])\n",
    "# Covariates\n",
    "xx1 = np.zeros((n1, dim1))\n",
    "for i in range(n1):\n",
    "    x = np.random.multivariate_normal(mean=x_centers1[:,cc1[i]],\n",
    "        cov=x_var1*np.identity(dim1))\n",
    "    xx1[i,:] = x\n",
    "# Data points\n",
    "yy1 = np.zeros(n1)\n",
    "for i in range(n1):\n",
    "    y = np.random.normal(loc=y_centers1[cc1[i]], scale=y_var1)\n",
    "    yy1[i] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20201125)\n",
    "perc_train1 = 0.75\n",
    "# Generate booleans\n",
    "n_train1 = int(perc_train1 * n1)\n",
    "idxs1 = np.arange(n1)\n",
    "training_mask1 = np.zeros(n1, dtype=bool)\n",
    "train_idxs1 = np.random.choice(idxs1, size=n_train1, replace=False)\n",
    "training_mask1[train_idxs1] = True\n",
    "# Train and test sets\n",
    "xx_train1 = xx1[training_mask1]\n",
    "yy_train1 = yy1[training_mask1]\n",
    "xx_test1 = xx1[~training_mask1]\n",
    "yy_test1 = yy1[~training_mask1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_np(\"../resources/csv/in/logsb_cov_mix_1.csv\", xx_train1)\n",
    "save_np(\"../resources/csv/in/logsb_data_1.csv\", yy_train1)\n",
    "save_np(\"../resources/csv/in/logsb_grid_cov_mix_1.csv\", np.matrix(xx_test1[0]))\n",
    "save_np(\"../resources/csv/in/logsb_grid_data_1.csv\", yy_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the executable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = ('../build/run ../algo_settings.asciipb '\n",
    "    'NNIG ../resources/asciipb/nnig_ngg_prior.asciipb '\n",
    "    'LogSB ../resources/asciipb/lsb_normal_prior.asciipb test1.recordio '\n",
    "    '../resources/csv/in/logsb_data_1.csv ../resources/csv/in/logsb_grid_data_1.csv '\n",
    "    '../resources/csv/out/logsb_dens_1.csv ../resources/csv/out/logsb_nclu_1.csv '\n",
    "    '../resources/csv/out/logsb_clus_1.csv \"\" \"\" '\n",
    "    '../resources/csv/in/logsb_cov_mix_1.csv '\n",
    "    '../resources/csv/in/logsb_grid_cov_mix_1.csv').split()\n",
    "subprocess.run(cmd, capture_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim2 = 2\n",
    "n_clus2 = 3\n",
    "alphas2 = np.identity(n_clus2-1)\n",
    "x_mean2 = np.array(dim2*[1])\n",
    "x_var2 = (1.5)**2\n",
    "y_centers2 = [4*_ for _ in range(n_clus2)]\n",
    "y_var2 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20201126)\n",
    "n2 = 200\n",
    "# Covariates\n",
    "xx2 = np.random.multivariate_normal(mean=x_mean2,\n",
    "    cov=x_var2*np.identity(dim2), size=n2)\n",
    "# Data points\n",
    "yy2 = np.zeros(n2)\n",
    "cc2 = np.zeros(n2, dtype=int)\n",
    "for i in range(n2):\n",
    "    ## Generate nu_h(xi)\n",
    "    nu = np.zeros(n_clus2-1)\n",
    "    for h in range(n_clus2-1):\n",
    "        nu[h] = sigmoid(np.dot(alphas2[:, h], xx2[i]))\n",
    "    ## Generate weights\n",
    "    weights = np.zeros(n_clus2)\n",
    "    for h in range(n_clus2-1):\n",
    "        weights[h] = nu[h]\n",
    "        for k in range(h):\n",
    "            weights[h] *= 1-nu[k]\n",
    "    weights[n_clus2-1] = 1 - weights[:n_clus2-1].sum()\n",
    "    ## Choose cluster and generate yi\n",
    "    c = np.random.choice(n_clus2, p=weights)\n",
    "    cc2[i] = c\n",
    "    yy2[i] = np.random.normal(loc=y_centers2[c], scale=y_var2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20201127)\n",
    "perc_train2 = 0.75\n",
    "# Generate booleans\n",
    "n_train2 = int(0.75 * n2)\n",
    "idxs2 = np.arange(n2)\n",
    "training_mask2 = np.zeros(n2, dtype=bool)\n",
    "train_idxs2 = np.random.choice(idxs2, size=n_train2, replace=False)\n",
    "training_mask2[train_idxs2] = True\n",
    "# Train and test sets\n",
    "xx_train2 = xx2[training_mask2]\n",
    "yy_train2 = yy2[training_mask2]\n",
    "xx_test2 = xx2[~training_mask2]\n",
    "yy_test2 = yy2[~training_mask2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_np(\"../resources/csv/in/logsb_cov_mix_2.csv\", xx_train2)\n",
    "save_np(\"../resources/csv/in/logsb_data_2.csv\", yy_train2)\n",
    "save_np(\"../resources/csv/in/logsb_grid_cov_mix_2.csv\", np.matrix(xx_test2[0]))\n",
    "save_np(\"../resources/csv/in/logsb_grid_data_2.csv\", yy_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the executable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = ('../build/run ../algo_settings.asciipb '\n",
    "    'NNIG ../resources/asciipb/nnig_ngg_prior.asciipb '\n",
    "    'LogSB ../resources/asciipb/lsb_normal_prior.asciipb test2.recordio '\n",
    "    '../resources/csv/in/logsb_data_2.csv ../resources/csv/in/logsb_grid_data_2.csv '\n",
    "    '../resources/csv/out/logsb_dens_2.csv ../resources/csv/out/logsb_nclu_2.csv '\n",
    "    '../resources/csv/out/logsb_clus_2.csv \"\" \"\" '\n",
    "    '../resources/csv/in/logsb_cov_mix_2.csv '\n",
    "    '../resources/csv/in/logsb_grid_cov_mix_2.csv').split()\n",
    "subprocess.run(cmd, capture_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot densities on test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read density matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr1 = np.genfromtxt(\"../resources/csv/out/logsb_dens_1.csv\", delimiter=',')\n",
    "matr2 = np.genfromtxt(\"../resources/csv/out/logsb_dens_2.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(16,6))\n",
    "\n",
    "ax1.scatter(yy_test1, np.exp(np.mean(matr1, axis=0)))\n",
    "ax1.set_title(f\"Test 1 density\")\n",
    "\n",
    "ax2.scatter(yy_test2, np.exp(np.mean(matr2, axis=0)))\n",
    "ax2.set_title(f\"Test 2 density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare clustering on train sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read posterior clusterings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust1 = np.genfromtxt(\"../resources/csv/out/logsb_clus_1.csv\",\n",
    "    delimiter=',').astype(int)\n",
    "clust2 = np.genfromtxt(\"../resources/csv/out/logsb_clus_2.csv\",\n",
    "    delimiter=',').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Adjusted Rand Indexes by comparison with true clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_clust1 = [cc1[i] for i in train_idxs1]\n",
    "true_clust2 = [cc2[i] for i in train_idxs2]\n",
    "ari1 = adjusted_rand_score(clust1, true_clust1)\n",
    "ari2 = adjusted_rand_score(clust2, true_clust2)\n",
    "print(ari1)\n",
    "print(ari2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File collectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read chain from file collectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = readManyFromFile(\"../test1.recordio\", AlgorithmState)\n",
    "chain2 = readManyFromFile(\"../test2.recordio\", AlgorithmState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(chain1), 100):\n",
    "    means = []\n",
    "    for j in range(len(chain1[i].cluster_states)):\n",
    "        means.append(chain1[i].cluster_states[j].uni_ls_state.mean)\n",
    "    print(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(chain2), 50):\n",
    "    means = []\n",
    "    for j in range(len(chain2[i].cluster_states)):\n",
    "        means.append(chain2[i].cluster_states[j].uni_ls_state.mean)\n",
    "    print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
